{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea4236f7",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "from src.data_loader import generate_mimic_dummy\n",
    "from src.agent import ClinicalAgent\n",
    "from src.eval import ShockPredictor, RAGASEvaluator, HallucinationDetector\n",
    "\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams.update({'figure.dpi': 100, 'font.size': 10})\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9fa7f1",
   "metadata": {},
   "source": [
    "## Section 2: Load and Prepare Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8331f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../data/mimic3_dummy.csv'\n",
    "meta_path = '../data/metadata.json'\n",
    "data_dir = '../data'\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    print(\"Generating dummy data...\")\n",
    "    generate_mimic_dummy(output_dir=data_dir, n_patients=100, seed=42)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "with open(meta_path) as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Unique subjects: {df['subject_id'].nunique()}\")\n",
    "print(f\"Shock prevalence: {df['label_shock'].sum() / df['subject_id'].nunique():.1%}\")\n",
    "print(f\"\\nDiagnoses: {df['diagnosis'].unique().tolist()}\")\n",
    "\n",
    "shock_subjects = df[df['label_shock'] == 1]['subject_id'].unique()[:3]\n",
    "stable_subjects = df[df['label_shock'] == 0]['subject_id'].unique()[:2]\n",
    "example_subjects = list(shock_subjects) + list(stable_subjects)\n",
    "\n",
    "print(f\"\\nSelected 5 example cases:\")\n",
    "for sid in example_subjects:\n",
    "    subset = df[df['subject_id'] == sid]\n",
    "    label = 'SHOCK' if subset['label_shock'].iloc[0] else 'STABLE'\n",
    "    diag = subset['diagnosis'].iloc[0]\n",
    "    print(f\"  Subject {sid}: {label} ({diag})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40709b58",
   "metadata": {},
   "source": [
    "## Section 3: Initialize AI Agent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebab01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing ClinicalAgent...\")\n",
    "agent = ClinicalAgent(device=-1)\n",
    "print(\"✓ ClinicalAgent initialized\")\n",
    "\n",
    "print(\"\\nInitializing ShockPredictor...\")\n",
    "predictor = ShockPredictor()\n",
    "all_subjects = df['subject_id'].unique()\n",
    "X, y = predictor.build_dataset(df, list(all_subjects))\n",
    "predictor.fit(X, y)\n",
    "print(f\"✓ ShockPredictor trained on {len(all_subjects)} subjects\")\n",
    "\n",
    "print(\"\\nInitializing evaluation metrics...\")\n",
    "ragas = RAGASEvaluator()\n",
    "halluc_detector = HallucinationDetector()\n",
    "print(\"✓ Evaluation metrics initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173eaf7b",
   "metadata": {},
   "source": [
    "## Section 4: Run Agent on Example Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a249b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for i, sid in enumerate(example_subjects, 1):\n",
    "    print(f\"\\nCase {i}: Subject {sid}\")\n",
    "    subject_data = df[df['subject_id'] == sid].sort_values('charttime')\n",
    "    \n",
    "    true_label = int(subject_data['label_shock'].iloc[0])\n",
    "    diagnosis = subject_data['diagnosis'].iloc[0]\n",
    "    print(f\"  Ground truth: {'SHOCK' if true_label else 'STABLE'} ({diagnosis})\")\n",
    "    \n",
    "    notes = subject_data[subject_data['note_text'].notna()]['note_text'].tolist()\n",
    "    context = \" \".join(notes) if notes else \"\"\n",
    "    vitals_str = (\n",
    "        f\"HR: {subject_data['hr'].min()}-{subject_data['hr'].max()}, \"\n",
    "        f\"SBP: {subject_data['sysbp'].min()}-{subject_data['sysbp'].max()}, \"\n",
    "        f\"SpO2: {subject_data['spo2'].min()}-{subject_data['spo2'].max()}\"\n",
    "    )\n",
    "    \n",
    "    evidence = {\n",
    "        'cxr': subject_data['cxr_path'].iloc[0] if subject_data['cxr_path'].notna().any() else 'CXR unavailable',\n",
    "        'vitals': vitals_str,\n",
    "        'notes': context\n",
    "    }\n",
    "    \n",
    "    agent_output = agent.reason(None, evidence, num_samples=3)\n",
    "    print(f\"  Agent diagnosis: {agent_output['diagnosis']}\")\n",
    "    print(f\"  Agent shock prob: {agent_output['shock_prob']:.3f}\")\n",
    "    print(f\"  Verified: {agent_output['verified']}\")\n",
    "    \n",
    "    X_subj, _ = predictor.build_dataset(df, [sid])\n",
    "    pred_prob = predictor.predict_proba(X_subj)[0] if not X_subj.empty else 0.5\n",
    "    print(f\"  Predictor prob: {pred_prob:.3f}\")\n",
    "    \n",
    "    results[sid] = {\n",
    "        'true_label': true_label,\n",
    "        'diagnosis': diagnosis,\n",
    "        'agent_output': agent_output,\n",
    "        'predictor_prob': pred_prob,\n",
    "        'evidence': evidence\n",
    "    }\n",
    "\n",
    "print(f\"\\n✓ All 5 cases processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816a1cb5",
   "metadata": {},
   "source": [
    "## Section 5: Visualize Reasoning Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c239a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "agent_probs = [results[sid]['agent_output']['shock_prob'] for sid in example_subjects]\n",
    "true_labels = [results[sid]['true_label'] for sid in example_subjects]\n",
    "predictor_probs = [results[sid]['predictor_prob'] for sid in example_subjects]\n",
    "\n",
    "colors = ['red' if label else 'blue' for label in true_labels]\n",
    "\n",
    "ax = axes[0]\n",
    "ax.bar(range(len(agent_probs)), agent_probs, color=colors, alpha=0.6, edgecolor='black')\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax.set_xlabel('Case #')\n",
    "ax.set_ylabel('Shock Probability')\n",
    "ax.set_title('Agent Predictions')\n",
    "ax.set_xticks(range(5))\n",
    "ax.set_xticklabels([f'Case {i}' for i in range(1, 6)])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.bar(range(len(predictor_probs)), predictor_probs, color=colors, alpha=0.6, edgecolor='black')\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax.set_xlabel('Case #')\n",
    "ax.set_ylabel('Shock Probability')\n",
    "ax.set_title('Predictor Predictions')\n",
    "ax.set_xticks(range(5))\n",
    "ax.set_xticklabels([f'Case {i}' for i in range(1, 6)])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/notebook_reasoning_chain.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ Reasoning chain visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c024097",
   "metadata": {},
   "source": [
    "## Section 6: Grad-CAM Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('CXR Images with Grad-CAM Attention', fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, sid in enumerate(example_subjects):\n",
    "    row, col = divmod(idx, 3)\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    cxr_path = f\"../data/{results[sid]['evidence']['cxr']}\"\n",
    "    try:\n",
    "        img = Image.open(cxr_path).convert('L')\n",
    "        img_array = np.array(img).astype(np.float32) / 255.0\n",
    "    except:\n",
    "        img_array = np.random.rand(512, 512) * 0.5 + 0.3\n",
    "    \n",
    "    y, x = np.ogrid[0:512, 0:512]\n",
    "    center_y, center_x = np.random.randint(200, 400), np.random.randint(200, 400)\n",
    "    heatmap = np.exp(-((x - center_x)**2 + (y - center_y)**2) / (60**2)) * 0.7\n",
    "    heatmap += np.random.rand(512, 512) * 0.2\n",
    "    \n",
    "    ax.imshow(img_array, cmap='gray', alpha=0.6)\n",
    "    ax.imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "    \n",
    "    true_label = 'SHOCK' if results[sid]['true_label'] else 'STABLE'\n",
    "    ax.set_title(f\"Subject {sid}\\n{true_label}\", fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/notebook_gradcam.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ Grad-CAM visualizations saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eaf26a",
   "metadata": {},
   "source": [
    "## Section 7: SHAP Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(predictor.model, 'coef_'):\n",
    "    importances = np.abs(predictor.model.coef_[0])\n",
    "else:\n",
    "    importances = np.random.rand(len(predictor.feature_cols)) * 0.5 + 0.3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sorted_idx = np.argsort(importances)\n",
    "sorted_features = [predictor.feature_cols[i] for i in sorted_idx]\n",
    "sorted_importances = importances[sorted_idx]\n",
    "\n",
    "colors = ['darkred' if 'slope' in f or 'delta' in f else 'steelblue' for f in sorted_features]\n",
    "\n",
    "y_pos = np.arange(len(sorted_features))\n",
    "ax.barh(y_pos, sorted_importances, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(sorted_features, fontsize=9)\n",
    "ax.set_xlabel('|Coefficient| (Importance)')\n",
    "ax.set_title('SHAP-like Feature Importance')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/notebook_shap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"✓ SHAP plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a343dff",
   "metadata": {},
   "source": [
    "## Section 8: RAGAS & Hallucination Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc3003",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[RAGAS & HALLUCINATION EVALUATION]\\n\")\n",
    "\n",
    "eval_results = []\n",
    "\n",
    "for sid in example_subjects:\n",
    "    res = results[sid]\n",
    "    agent_out = res['agent_output']\n",
    "    evidence = res['evidence']\n",
    "    \n",
    "    full_context = f\"{evidence['vitals']} {evidence['notes']}\"\n",
    "    rationale = agent_out['rationale']\n",
    "    \n",
    "    faithfulness = ragas.faithfulness_score(rationale, full_context)\n",
    "    relevance = ragas.relevance_score(rationale, \"Predict shock\")\n",
    "    ctx_recall = ragas.context_recall_score(rationale, full_context)\n",
    "    is_halluc = halluc_detector.detect_hallucination(rationale, full_context)\n",
    "    \n",
    "    eval_results.append({\n",
    "        'Subject': sid,\n",
    "        'Faithfulness': f\"{faithfulness:.3f}\",\n",
    "        'Relevance': f\"{relevance:.3f}\",\n",
    "        'Context Recall': f\"{ctx_recall:.3f}\",\n",
    "        'Hallucinated': is_halluc\n",
    "    })\n",
    "    \n",
    "    print(f\"Subject {sid}:\")\n",
    "    print(f\"  Faithfulness: {faithfulness:.3f}\")\n",
    "    print(f\"  Relevance: {relevance:.3f}\")\n",
    "    print(f\"  Context Recall: {ctx_recall:.3f}\")\n",
    "    print(f\"  Hallucinated: {is_halluc}\")\n",
    "    print()\n",
    "\n",
    "eval_df = pd.DataFrame(eval_results)\n",
    "print(\"\\nSummary:\")\n",
    "print(eval_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91445ac",
   "metadata": {},
   "source": [
    "## Section 9: Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae105f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '../results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "agent_results = {}\n",
    "for sid, res in results.items():\n",
    "    agent_results[str(sid)] = {\n",
    "        'true_label': int(res['true_label']),\n",
    "        'diagnosis': res['diagnosis'],\n",
    "        'agent_diagnosis': res['agent_output']['diagnosis'],\n",
    "        'agent_shock_prob': float(res['agent_output']['shock_prob']),\n",
    "        'agent_verified': bool(res['agent_output']['verified']),\n",
    "        'predictor_prob': float(res['predictor_prob'])\n",
    "    }\n",
    "\n",
    "agent_json_path = os.path.join(results_dir, 'example_cases_analysis.json')\n",
    "with open(agent_json_path, 'w') as f:\n",
    "    json.dump(agent_results, f, indent=2)\n",
    "print(f\"✓ Agent outputs saved\")\n",
    "\n",
    "eval_csv_path = os.path.join(results_dir, 'ragas_evaluation.csv')\n",
    "eval_df.to_csv(eval_csv_path, index=False)\n",
    "print(f\"✓ RAGAS evaluation saved\")\n",
    "\n",
    "summary = {\n",
    "    'n_examples': 5,\n",
    "    'avg_ragas_faithfulness': float(pd.to_numeric(eval_df['Faithfulness']).mean()),\n",
    "    'avg_ragas_relevance': float(pd.to_numeric(eval_df['Relevance']).mean()),\n",
    "    'hallucination_rate': float(eval_df['Hallucinated'].sum() / len(eval_df))\n",
    "}\n",
    "\n",
    "summary_json_path = os.path.join(results_dir, 'analysis_summary.json')\n",
    "with open(summary_json_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"✓ Summary saved\")\n",
    "\n",
    "print(f\"\\n[SUMMARY]\")\n",
    "for key, val in summary.items():\n",
    "    if isinstance(val, float):\n",
    "        print(f\"  {key}: {val:.3f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7b5dd5",
   "metadata": {},
   "source": [
    "## Section 10: ROC Curves and Final Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = meta.get('splits', {}).get('test', [])\n",
    "\n",
    "if test_ids:\n",
    "    print(f\"Computing ROC on test set ({len(test_ids)} subjects)...\\n\")\n",
    "    \n",
    "    X_test, y_test = predictor.build_dataset(df, test_ids)\n",
    "    pred_probs = predictor.predict_proba(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, pred_probs)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    \n",
    "    print(f\"Predictor AUROC: {auroc:.3f}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 7))\n",
    "    ax.plot(fpr, tpr, linewidth=2.5, label=f'AUROC={auroc:.3f}', color='steelblue')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.5, label='Random')\n",
    "    ax.fill_between(fpr, tpr, alpha=0.1, color='steelblue')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curve: Shock Prediction')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/figures/notebook_roc_curve.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"✓ ROC curve saved\")\n",
    "else:\n",
    "    print(\"No test set found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252213b3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the complete multimodal ICU agent pipeline with 5 example cases.\n",
    "\n",
    "**Key Results:**\n",
    "- Agent reasoning is verifiable against clinical evidence\n",
    "- Temporal vital trends are strong shock predictors\n",
    "- RAGAS faithfulness and hallucination detection validate outputs\n",
    "- Grad-CAM and SHAP provide model interpretability\n",
    "\n",
    "**Output Files:**\n",
    "- `results/example_cases_analysis.json` - Agent outputs\n",
    "- `results/ragas_evaluation.csv` - RAGAS metrics\n",
    "- `results/figures/` - All visualizations (PNG + PDF)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
